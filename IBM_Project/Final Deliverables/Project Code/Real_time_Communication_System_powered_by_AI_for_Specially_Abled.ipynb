{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Image Preprocessing"
      ],
      "metadata": {
        "id": "uBUJ8hIaRF4x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "5D9Oyy7PbMx0"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DwnQ6_ihM0m",
        "outputId": "49ad4b14-1a13-4134-b3b4-12e357f08705"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ulGiuiogdsT",
        "outputId": "dca4f3a1-2c24-432d-fb66-1b7ce2939a08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open Dataset.zip, Dataset.zip.zip or Dataset.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!unzip Dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image Data Generator Functionality to train and test set"
      ],
      "metadata": {
        "id": "vdWafYKHRMhS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvcVRcYDdwxW",
        "outputId": "1855d9b7-5633-4aaa-97c1-28a686f05247"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 15768 images belonging to 9 classes.\n",
            "Found 2250 images belonging to 9 classes.\n"
          ]
        }
      ],
      "source": [
        "x_train=train_datagen.flow_from_directory('/content/drive/MyDrive/Dataset/Dataset/training_set',target_size=(64,64),batch_size=300,class_mode='categorical',color_mode='grayscale')\n",
        "x_test=test_datagen.flow_from_directory('/content/drive/MyDrive/Dataset/Dataset/test_set',target_size=(64,64),batch_size=300,class_mode='categorical',color_mode='grayscale')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Building"
      ],
      "metadata": {
        "id": "KQU0lxRURlm4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the required Libraries"
      ],
      "metadata": {
        "id": "ET4x3NBaRs5_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "5OhmMUMnfi9J"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the model"
      ],
      "metadata": {
        "id": "ytjT3Yb0RxFU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rzN5bCZfplSa"
      },
      "outputs": [],
      "source": [
        "model=Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding Convolution Layer"
      ],
      "metadata": {
        "id": "-3GBpzppRzIq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "X8GlcbFcptXP"
      },
      "outputs": [],
      "source": [
        "model.add(Convolution2D(32,(3,3),input_shape=(64,64,1),activation='relu'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding Pooling Layer"
      ],
      "metadata": {
        "id": "sgTyrATJR21-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yrvo_CI6p71i"
      },
      "outputs": [],
      "source": [
        "model.add(MaxPooling2D(pool_size=(2,2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding Flatten Layer"
      ],
      "metadata": {
        "id": "Lw2bWH69R-JI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dJywRQxIqEbF"
      },
      "outputs": [],
      "source": [
        "model.add(Flatten())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding Dense Layer"
      ],
      "metadata": {
        "id": "QoQKOlOaSAkY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WmCSJ0QKqIeL"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(units=512,activation='relu'))\n",
        "model.add(Dense(units=9,activation='Softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the Model"
      ],
      "metadata": {
        "id": "_ptl9ichSDdE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zMN3fn_aqVhs"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit and Save the model"
      ],
      "metadata": {
        "id": "79HtEq6fSHnW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGRdB3wgqh_l",
        "outputId": "8362f225-d17e-489b-fabc-fff24601d79b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.9502 - accuracy: 0.7001 "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 40 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1695s 71s/step - loss: 0.9502 - accuracy: 0.7001 - val_loss: 0.3483 - val_accuracy: 0.9151\n",
            "Epoch 2/10\n",
            "24/24 [==============================] - 659s 27s/step - loss: 0.2261 - accuracy: 0.9359\n",
            "Epoch 3/10\n",
            "24/24 [==============================] - 357s 15s/step - loss: 0.1212 - accuracy: 0.9668\n",
            "Epoch 4/10\n",
            "24/24 [==============================] - 195s 8s/step - loss: 0.0710 - accuracy: 0.9832\n",
            "Epoch 5/10\n",
            "24/24 [==============================] - 110s 5s/step - loss: 0.0534 - accuracy: 0.9856\n",
            "Epoch 6/10\n",
            "24/24 [==============================] - 64s 3s/step - loss: 0.0348 - accuracy: 0.9929\n",
            "Epoch 7/10\n",
            "24/24 [==============================] - 47s 2s/step - loss: 0.0213 - accuracy: 0.9956\n",
            "Epoch 8/10\n",
            "24/24 [==============================] - 33s 1s/step - loss: 0.0200 - accuracy: 0.9946\n",
            "Epoch 9/10\n",
            "24/24 [==============================] - 28s 1s/step - loss: 0.0145 - accuracy: 0.9965\n",
            "Epoch 10/10\n",
            "24/24 [==============================] - 25s 1s/step - loss: 0.0113 - accuracy: 0.9980\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb5aca6f190>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "model.fit_generator(x_train,steps_per_epoch=24,epochs=10,validation_data=x_test,validation_steps=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Gyf7DtGGqy26"
      },
      "outputs": [],
      "source": [
        "model.save('aslpng1.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the Model"
      ],
      "metadata": {
        "id": "yq1VJIdgSL8s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Packages and Load saved Model"
      ],
      "metadata": {
        "id": "j_c2fpsuSOUN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "zRevf39H4Z9q"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=load_model('model.h5')"
      ],
      "metadata": {
        "id": "avXWZpQZAYz8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the Test Image, Preprocessing and Predicting"
      ],
      "metadata": {
        "id": "5u-5Tnq-SmzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.transform import resize"
      ],
      "metadata": {
        "id": "1S6TMlucklq9"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install igraph"
      ],
      "metadata": {
        "id": "eG4wiAuX7E0-",
        "outputId": "404a1fbc-e002-4f5d-f4e0-1808566a88a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting igraph\n",
            "  Downloading igraph-0.10.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 24.8 MB/s \n",
            "\u001b[?25hCollecting texttable>=1.6.2\n",
            "  Downloading texttable-1.6.4-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: texttable, igraph\n",
            "Successfully installed igraph-0.10.2 texttable-1.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def detect(frame):\n",
        "  img=resize(frame,(64,64,1))\n",
        "  img=np.expand_dims(img,axis=0)\n",
        "  if(np.max(img)>1):\n",
        "    img=img/255.0\n",
        "  prediction=model.predict(img)\n",
        "  print(prediction)"
      ],
      "metadata": {
        "id": "ojVsBRFUsxph"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame=cv2.imread(r'/content/drive/MyDrive/Dataset/Dataset/test_set/I/1.png')\n",
        "data=detect(frame)\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(frame)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "sebxVscdA3EB",
        "outputId": "ab39d797-3004-4f79-d14f-282c66980086"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "[[7.3589194e-07 3.1176359e-07 2.9840255e-08 3.4123502e-07 4.7846964e-07\n",
            "  7.3650303e-06 9.4001713e-09 2.0357358e-08 9.9999070e-01]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7FB5964E8410>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAACfElEQVR4nO2aLc/iQBDHt5czoEhoAgjQBYWoqEIhCAZFUouCD0DAgsBgEQj4ADiCwqAwxfIFIChIGkJCSEAQ9kRz3D19LtftzuzuPbn+VOnLzH+2MzvTBEIiIiIiwmHbNqXUtm3VQriYTqf0J4VCAW5Qg5sIBaX0g3sNKuAb8HnlRAGoRmoApmmi25QagK7rv/8cDocyvSNQqVToR1QrColPfafTgduU2gc+L3nUBwQHkEql0um0d2xZlu/q9XoV6p0VwzAopd1u13fedd13uhuGYVmWrwaazaYSwb9IJBI+Tclk0rtEGUAJAJRCl8vFd6bdbhNCHMeBmBWIbdv1et07ZlljCW+AlePx+HbcarVQAvDsAGFKocPh8N5MCCHj8Zj+M000OIBGo5HL5SRI4SM4gH6/L0EHN8EBZLNZQb5R8vDLjxLBs5TQepUxzImr4F6vBzfCtADiXoKkcXqz2QDd/BGURsaE4zjs/ZUQQim93++v14vlZiBCdiFN02KxmOu6gXfWajWgr+/A5z8Tal0XiwXQHWsNCapjXdfP5zPEguIAJO1C5XIZ6EYxu92OY9xn3LJkIEi9pA+a5XIJdyOOLz+NqgxgtVrJcGOapqAaQJGnchqFNwHCmELb7RbuyUc+n0e3+Tdwk2c0GmEJU1PEt9sNyxRrACKyCAXWAIrFokgZ/IRIodPpJE4HNyECyGQy4nRwE66IH4+HIB3chG4lKE0NpYV5hN5GJ5MJ0OV6vQZagALsYvP5HFEMTyMbDAYQl+o3g3g8DnkDpVIJUQxnMUFKGbGCifxZaDab4Rr8Xz8pq9Uqrg5uOAPY7/e4OmTj/cGDg+fziavkBxL35ueCiIF+AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PjhGzGmjxOZ3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}